{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "# load the training and test datasets\n",
    "train_data = datasets.MNIST(root='~/.pytorch/MNIST_data/', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='~/.pytorch/MNIST_data/', train=False,\n",
    "                                  download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test dataloaders\n",
    "\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.__next__()\n",
    "images = images.numpy()\n",
    "\n",
    "# Plot the images in a 2x5 grid\n",
    "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(12, 6))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    img = np.squeeze(images[i])\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title('Image {}'.format(i+1))\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvAutoencoder(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (t_conv1): ConvTranspose2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (t_conv2): ConvTranspose2d(16, 1, kernel_size=(2, 2), stride=(2, 2))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        ## encoder layers ##\n",
    "        # conv layer (depth from 1 --> 16), 3x3 kernels\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)  \n",
    "        # conv layer (depth from 16 --> 4), 3x3 kernels\n",
    "        self.conv2 = nn.Conv2d(16, 4, 3, padding=1)\n",
    "        # pooling layer to reduce x-y dims by two; kernel and stride of 2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        ## decoder layers ##\n",
    "        ## a kernel of 2 and a stride of 2 will increase the spatial dims by 2\n",
    "        self.t_conv1 = nn.ConvTranspose2d(4, 16, 2, stride=2)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(16, 1, 2, stride=2)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## encode ##\n",
    "        # add hidden layers with relu activation function\n",
    "        # and maxpooling after\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        # add second hidden layer\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)  # compressed representation\n",
    "        \n",
    "        ## decode ##\n",
    "        # add transpose conv layers, with relu activation function\n",
    "        x = F.relu(self.t_conv1(x))\n",
    "        # output layer (with sigmoid for scaling from 0 to 1)\n",
    "        x = F.sigmoid(self.t_conv2(x))\n",
    "                \n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "model = ConvAutoencoder()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# specify loss function\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# specify loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# specify loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m\n\u001b[0;32m      9\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m###################\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# train the model #\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m###################\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_loader\u001b[49m:\n\u001b[0;32m     15\u001b[0m     images, _ \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the training losses\n",
    "train_losses = []\n",
    "\n",
    "# Set the number of epochs\n",
    "n_epochs = 30\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data in train_loader:\n",
    "        images, _ = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "    \n",
    "    # Calculate the average training loss for the epoch\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Print the average training loss for the epoch\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "\n",
    "# Plot the training loss as a function of epochs\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss vs. Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a deeper model to get better results #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepConvAutoencoder(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fully_connected): Linear(in_features=12, out_features=12, bias=True)\n",
      "  (t_conv1): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (t_conv2): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (t_conv3): ConvTranspose2d(32, 1, kernel_size=(2, 2), stride=(2, 2))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DeepConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepConvAutoencoder, self).__init__()\n",
    "        ## encoder layers ##\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)  \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fully_connected = nn.Linear(12,12)\n",
    "        \n",
    "        ## decoder layers ##\n",
    "        self.t_conv1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
    "        self.t_conv3 = nn.ConvTranspose2d(32, 1, 2, stride=2)\n",
    "        self.fully_connected = nn.Linear(12,12)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## encode ##\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)  # compressed representation\n",
    "        \n",
    "        ## decode ##\n",
    "        x = F.relu(self.t_conv1(x))\n",
    "        x = F.relu(self.t_conv2(x))\n",
    "        x = F.sigmoid(self.t_conv3(x))  # output layer with sigmoid activation\n",
    "                \n",
    "        return x\n",
    "\n",
    "# Initialize the deep convolutional autoencoder\n",
    "deep_autoencoder = DeepConvAutoencoder()\n",
    "print(deep_autoencoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model and plot the training loss curve #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.018681\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m outputs_resized \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(outputs, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs_resized, images)\n\u001b[1;32m---> 31\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     33\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nicka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize your deep autoencoder model\n",
    "deep_autoencoder = DeepConvAutoencoder()\n",
    "\n",
    "# Specify the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Specify the optimizer\n",
    "optimizer = torch.optim.Adam(deep_autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "# Initialize an empty list to store the training losses\n",
    "train_losses = []\n",
    "\n",
    "# Set the number of epochs\n",
    "n_epochs = 4\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Train the model\n",
    "    for data in train_loader:\n",
    "        images, _ = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = deep_autoencoder(images)\n",
    "        \n",
    "        # Resize outputs to match the input size (28x28)\n",
    "        outputs_resized = F.interpolate(outputs, size=(28, 28), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        loss = criterion(outputs_resized, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    # Calculate the average training loss for the epoch\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Print the average training loss for the epoch\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "\n",
    "# Plot the training loss as a function of epochs\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss vs. Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See some results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# obtain one batch of test images\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[43mtest_loader\u001b[49m)\n\u001b[0;32m      3\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m dataiter\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__next__\u001b[39m()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# get sample outputs\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# obtain one batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.__next__()\n",
    "\n",
    "# get sample outputs\n",
    "outputs = deep_autoencoder(images)\n",
    "# prep images for display\n",
    "images = images.numpy()\n",
    "\n",
    "# output is resized into a batch of iages\n",
    "outputs_resized = F.interpolate(outputs, size=(28, 28), mode='bilinear', align_corners=False)\n",
    "# use detach when it's an output that requires_grad\n",
    "output = outputs_resized.detach().numpy()\n",
    "\n",
    "# plot the first ten input images and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))\n",
    "\n",
    "# input images on top row, reconstructions on bottom\n",
    "for images, row in zip([images, output], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(np.squeeze(img), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(True)\n",
    "        ax.get_yaxis().set_visible(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
